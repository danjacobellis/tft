{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12f030f8-c93a-496b-a75c-eb00395923cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "from types import SimpleNamespace\n",
    "from sklearn.metrics import average_precision_score\n",
    "from datasets import load_dataset, Audio\n",
    "from timm.optim import Mars\n",
    "from fastprogress import master_bar, progress_bar\n",
    "from torchvision.transforms.v2 import RandomCrop, CenterCrop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7eed2f-5070-4b87-beda-ed01bb82d0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('high')\n",
    "device=\"cuda:1\"\n",
    "audioset = load_dataset(\"danjacobellis/audioset_opus_24kbps\",split='train').cast_column('opus', Audio(decode=False))\n",
    "dataset_train = audioset.select(range(1800000))\n",
    "dataset_valid = audioset.select(range(1800000,audioset.num_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b696feaf-01ff-4d76-b562-9d8d9b905fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = SimpleNamespace()\n",
    "# Training and optimizer config\n",
    "config.batch_size = 128\n",
    "config.steps_per_epoch = dataset_train.num_rows//config.batch_size\n",
    "config.grad_accum_steps = 1\n",
    "config.max_lr = (config.batch_size/128)*6e-4\n",
    "config.min_lr = config.max_lr/100\n",
    "config.plot_update = 128\n",
    "config.epochs = 200\n",
    "config.lr_scale = 0.5\n",
    "config.lr_offset = 0.25\n",
    "config.lr_pow = 2\n",
    "config.weight_decay = 0.\n",
    "config.num_workers = 24\n",
    "config.audio_len = 483840\n",
    "config.crop_size = 512*512\n",
    "\n",
    "# model config\n",
    "config.channels = 1\n",
    "config.J = 10\n",
    "config.embed_dim = 256\n",
    "config.dim_head = 32\n",
    "config.exp_ratio = 4.0\n",
    "config.classifier_num_classes = 632"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2169b755-94e6-4693-9e4b-8ab1cee5b79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import einops\n",
    "from timm.models.maxxvit import LayerScale\n",
    "\n",
    "class RMSNormAct(torch.nn.Module):\n",
    "    def __init__(self, normalized_features):\n",
    "        super(RMSNormAct, self).__init__()\n",
    "        self.norm = torch.nn.RMSNorm(normalized_features)\n",
    "        self.act = torch.nn.GELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm(x)\n",
    "        x = self.act(x)\n",
    "        return x\n",
    "\n",
    "class InvertedResidual1D(torch.nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, sequence_dim, exp_ratio):\n",
    "        super(InvertedResidual1D, self).__init__()\n",
    "        self.exp_dim = int(in_dim * exp_ratio)\n",
    "        self.pw_exp = torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(in_dim, self.exp_dim, kernel_size=1, stride=1, bias=False),\n",
    "            RMSNormAct((self.exp_dim, sequence_dim))\n",
    "        )\n",
    "        self.dw_mid = torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(self.exp_dim, self.exp_dim, kernel_size=3, stride=1, padding=1, groups=self.exp_dim, bias=False),\n",
    "            RMSNormAct((self.exp_dim, sequence_dim))\n",
    "        )\n",
    "        self.se = torch.nn.Identity()\n",
    "        self.pw_proj = torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(self.exp_dim, out_dim, kernel_size=1, stride=1, bias=False),\n",
    "            torch.nn.RMSNorm((out_dim, sequence_dim)) \n",
    "        )\n",
    "        self.dw_end = torch.nn.Identity()\n",
    "        self.layer_scale = LayerScale(out_dim)\n",
    "        self.drop_path = torch.nn.Identity()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        shortcut = x if x.shape[1] == self.pw_proj[0].out_channels else None\n",
    "        x = self.pw_exp(x)\n",
    "        x = self.dw_mid(x)\n",
    "        x = self.se(x)\n",
    "        x = self.pw_proj(x)\n",
    "        x = self.dw_end(x)\n",
    "        x = self.layer_scale(x)\n",
    "        x = self.drop_path(x)\n",
    "        if shortcut is not None:\n",
    "            x += shortcut\n",
    "        return x\n",
    "\n",
    "class TransformerBlock1D(torch.nn.Module):\n",
    "    def __init__(self, embed_dim, dim_feedforward, nhead):\n",
    "        super().__init__()\n",
    "        self.layer = torch.nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=0.0,\n",
    "            activation='gelu',\n",
    "            batch_first=True\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = einops.rearrange(x, 'b c s -> b s c')\n",
    "        x = self.layer(x)\n",
    "        x = einops.rearrange(x, 'b s c -> b c s')\n",
    "        return x\n",
    "\n",
    "class AsCAN1D(torch.nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, sequence_dim, dim_head, exp_ratio):\n",
    "        super().__init__()\n",
    "        C=lambda:InvertedResidual1D(embed_dim, embed_dim, sequence_dim, exp_ratio)\n",
    "        T=lambda:TransformerBlock1D(embed_dim, int(exp_ratio*embed_dim), embed_dim//dim_head)\n",
    "        self.layers=torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(input_dim,embed_dim,kernel_size=1),\n",
    "            RMSNormAct((embed_dim, sequence_dim)),\n",
    "            C(),C(),C(),T(),\n",
    "            C(),C(),T(),T(),\n",
    "            C(),T(),T(),T()\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        return self.layers(x)\n",
    "\n",
    "class WaveletPooling1D(torch.nn.Module):\n",
    "    def __init__(self, embed_dim, sequence_dim, wpt, num_levels):\n",
    "        super().__init__()\n",
    "        self.wpt = wpt\n",
    "        self.num_levels = num_levels\n",
    "        current_sequence_dim = sequence_dim\n",
    "        self.projection_down = torch.nn.ModuleList()\n",
    "        for _ in range(num_levels):\n",
    "            self.projection_down.append(\n",
    "                torch.nn.Sequential(\n",
    "                    torch.nn.Conv1d(embed_dim, embed_dim // 2, kernel_size=1, padding=0),\n",
    "                    torch.nn.RMSNorm((embed_dim // 2, current_sequence_dim))\n",
    "                )\n",
    "            )\n",
    "            current_sequence_dim //= 2\n",
    "    def forward(self, x):\n",
    "        for i in range(self.num_levels):\n",
    "            x = self.projection_down[i](x)\n",
    "            x = self.wpt.analysis_one_level(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class TFTClassifier1D(torch.nn.Module):\n",
    "    def __init__(self, config, wpt):\n",
    "        super().__init__()\n",
    "        self.wpt = wpt\n",
    "        self.ascan = AsCAN1D(\n",
    "            input_dim=config.channels*(2**config.J),\n",
    "            embed_dim=config.embed_dim,\n",
    "            sequence_dim=config.crop_size//(2**config.J),\n",
    "            dim_head=config.dim_head,\n",
    "            exp_ratio=config.exp_ratio\n",
    "        )\n",
    "        self.pool = WaveletPooling1D(\n",
    "            embed_dim=config.embed_dim,\n",
    "            sequence_dim=config.crop_size//(2**config.J),\n",
    "            wpt=wpt,\n",
    "            num_levels=int(np.log2(config.crop_size) - config.J)\n",
    "        )\n",
    "        self.classifier = torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(config.embed_dim, config.classifier_num_classes, kernel_size=1),\n",
    "            torch.nn.Flatten()\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x = self.wpt(x)\n",
    "        x = self.ascan(x)\n",
    "        x = self.pool(x)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32328b3e-b482-4bb6-98d2-714f12cc24e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_wavelets import DWT1DForward\n",
    "from tft.transforms import WPT1D\n",
    "\n",
    "wt = DWT1DForward(J=1, mode='periodization', wave='bior4.4')\n",
    "wpt = WPT1D(wt,J=config.J).to(device)\n",
    "\n",
    "model = TFTClassifier1D(config,wpt).to(device)\n",
    "\n",
    "for name, module in model.named_children():\n",
    "    print(f\"{sum(p.numel() for p in module.parameters())/1e6} \\t {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fc70cd-7595-4c92-b48b-19de388ec6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_crop = RandomCrop(\n",
    "    size=(1,config.crop_size),\n",
    "    pad_if_needed=True,\n",
    ")\n",
    "\n",
    "cent_crop = CenterCrop(\n",
    "    size=(1,config.crop_size),\n",
    ")\n",
    "\n",
    "def train_collate_fn(batch):\n",
    "    B = len(batch)\n",
    "    x = torch.zeros((B, config.channels, 1, config.crop_size), dtype=torch.float)\n",
    "    y = []\n",
    "    for i_sample, sample in enumerate(batch):\n",
    "        y.append(sample['label'])\n",
    "        x_raw, fs = torchaudio.load(uri = sample['opus']['bytes'],normalize=False)\n",
    "        x[i_sample,:,:,:] = rand_crop(x_raw.unsqueeze(0).unsqueeze(0))\n",
    "    return x[:,:,0,:], y\n",
    "\n",
    "def valid_collate_fn(batch):\n",
    "    B = len(batch)\n",
    "    x = torch.zeros((B, config.channels, 1, config.crop_size), dtype=torch.float)\n",
    "    y = []\n",
    "    for i_sample, sample in enumerate(batch):\n",
    "        y.append(sample['label'])\n",
    "        x_raw, fs = torchaudio.load(uri = sample['opus']['bytes'],normalize=False)\n",
    "        x[i_sample,:,:,:] = cent_crop(x_raw.unsqueeze(0).unsqueeze(0))\n",
    "    return x[:,:,0,:], y\n",
    "\n",
    "def create_multi_hot_labels(batch_of_label_indices, num_classes):\n",
    "    batch_size = len(batch_of_label_indices)\n",
    "    labels = torch.zeros(batch_size, num_classes, dtype=torch.float32)\n",
    "    for i, sample_labels in enumerate(batch_of_label_indices):\n",
    "        indices = torch.tensor(sample_labels, dtype=torch.long)\n",
    "        labels[i].scatter_(0, indices, 1.0)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4261d29-041a-4fb8-a151-ed36a1b2f28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Mars(\n",
    "    params=model.parameters(),\n",
    "    lr=config.min_lr,\n",
    "    weight_decay=config.weight_decay,\n",
    "    caution=True\n",
    ")\n",
    "\n",
    "def EmPL(x):\n",
    "    return np.exp(-np.power(np.log(x), config.lr_pow))\n",
    "        \n",
    "def EmPL_sched(i_step, config):\n",
    "    x = i_step / (config.steps_per_epoch/config.plot_update)\n",
    "    sched = EmPL(x/(config.lr_scale*config.steps_per_epoch/config.plot_update)+config.lr_offset)\n",
    "    scale = config.max_lr\n",
    "    lr = scale * sched\n",
    "    return lr / config.min_lr\n",
    "    \n",
    "schedule = torch.optim.lr_scheduler.LambdaLR(\n",
    "    optimizer,\n",
    "    lr_lambda = lambda i_step: EmPL_sched(i_step, config),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289e4961-56c8-4d4a-a718-627122ee2993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_rates = [optimizer.param_groups[0]['lr']]\n",
    "# i_step = 0\n",
    "# for i_epoch in range(config.epochs):\n",
    "#     for i_batch in range(config.steps_per_epoch):\n",
    "#         if (i_step+1) % config.plot_update == 0:\n",
    "#             schedule.step()\n",
    "#             learning_rates.append(optimizer.param_groups[0]['lr'])\n",
    "#         i_step+=1\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.plot(learning_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4610696-9552-4cde-9110-778c47116645",
   "metadata": {},
   "outputs": [],
   "source": [
    "mb = master_bar(range(config.epochs))\n",
    "mb.names = ['per batch','smoothed']\n",
    "train_loss = []\n",
    "mAP = []\n",
    "learning_rates = [optimizer.param_groups[0]['lr']]\n",
    "i_step = 0\n",
    "for i_epoch in mb:\n",
    "    # training\n",
    "    model.train()\n",
    "    dataloader_train = torch.utils.data.DataLoader(\n",
    "        dataset_train,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=config.num_workers,\n",
    "        drop_last=True,\n",
    "        pin_memory=True,\n",
    "        collate_fn=train_collate_fn\n",
    "    )\n",
    "    pb = progress_bar(dataloader_train, parent=mb)\n",
    "    for i_batch, (x,y) in enumerate(pb):\n",
    "        x = x.to(device)\n",
    "        y = create_multi_hot_labels(y, config.classifier_num_classes).to(device)\n",
    "        logits = model(x)\n",
    "        loss = torch.nn.BCEWithLogitsLoss()(logits, y)\n",
    "\n",
    "        train_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        if (i_batch + 1) % config.grad_accum_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        # plotting and learning rate update\n",
    "        if (i_step+1) % config.plot_update == 0:\n",
    "            plot_n = len(train_loss) // config.plot_update\n",
    "            smoothed_x = (0.5+torch.arange(plot_n)) * config.plot_update\n",
    "            smoothed_y = torch.tensor(train_loss).reshape(plot_n, -1).mean(dim=1)\n",
    "            train_x = range(len(train_loss))\n",
    "            train_y = train_loss\n",
    "            mb.update_graph([[train_x, np.log10(train_y)],[smoothed_x, np.log10(smoothed_y)]])\n",
    "\n",
    "            # lr update\n",
    "            schedule.step()\n",
    "            learning_rates.append(optimizer.param_groups[0]['lr'])\n",
    "    \n",
    "        i_step+=1\n",
    "        \n",
    "    model.eval()\n",
    "    all_logits = []\n",
    "    all_labels = []\n",
    "    data_loader_valid = torch.utils.data.DataLoader(\n",
    "        dataset_valid,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=config.num_workers,\n",
    "        drop_last=False,\n",
    "        pin_memory=True,\n",
    "        collate_fn=valid_collate_fn\n",
    "    )\n",
    "    pb_valid = progress_bar(data_loader_valid, parent=mb)\n",
    "    for i_batch, (x, y) in enumerate(pb_valid):\n",
    "        x = x.to(device)\n",
    "        y = create_multi_hot_labels(y, config.classifier_num_classes).to(device)\n",
    "        with torch.no_grad():\n",
    "            logits = model(x)\n",
    "        all_logits.append(logits.cpu())\n",
    "        all_labels.append(y.cpu())\n",
    "    all_logits = torch.cat(all_logits, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    all_probs = all_logits.sigmoid().numpy()\n",
    "    all_labels_np = all_labels.numpy()    \n",
    "    ap_per_class = []\n",
    "    num_classes = all_probs.shape[1]\n",
    "    labels_per_class = np.sum(all_labels_np, axis=0)\n",
    "    for class_idx in range(num_classes):\n",
    "        if labels_per_class[class_idx] == 0:\n",
    "            ap = 0.0\n",
    "        else:\n",
    "            ap = average_precision_score(all_labels_np[:, class_idx],\n",
    "                                         all_probs[:, class_idx])\n",
    "        ap_per_class.append(ap)\n",
    "    mAP_value = np.mean(ap_per_class)\n",
    "    mAP.append(mAP_value)\n",
    "    mb.main_bar.comment = f'mAP {mAP_value:.4g}'\n",
    "\n",
    "    torch.save({\n",
    "        'i_epoch': i_epoch,\n",
    "        'learning_rates': learning_rates,\n",
    "        'smoothed_y': smoothed_y,\n",
    "        'mAP': mAP,\n",
    "        'config': config,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "    }, f\"log_{device}.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
