{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a303338e-3082-4d05-bc7a-2875aee8bc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset\n",
    "from torchvision.transforms.v2 import (\n",
    "    Compose, RandomResizedCrop, RandomHorizontalFlip, CutMix, MixUp,\n",
    "    Resize, CenterCrop, PILToTensor, RandAugment\n",
    ")\n",
    "from timm.optim import AdamW\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import math\n",
    "from fastprogress import progress_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43efdee-e705-4e4c-bca0-c430e1eab0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class config:\n",
    "    crop_size = 160\n",
    "    valid_crop_size = 256\n",
    "    channels = 3\n",
    "    batch_size = 128\n",
    "    lr = 1e-3\n",
    "    weight_decay = 0.05\n",
    "    warmup_epochs = 20\n",
    "    epochs = 100\n",
    "    mixup_alpha = 0.8\n",
    "    cutmix_alpha = 1.0\n",
    "    label_smoothing = 0.1\n",
    "    ema_decay = 0.9999\n",
    "    grad_clip = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7d710b-97d4-47d9-87e2-93ff9ff15c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(channels, channels//reduction, 1),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(channels//reduction, channels, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x * self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b75a004-1a2b-40c1-b437-b74ac04d4e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridBlock(nn.Module):\n",
    "    def __init__(self, dim, expansion=4, drop_path=0.):\n",
    "        super().__init__()\n",
    "        self.dwconv = nn.Conv2d(dim, dim, 7, padding=3, groups=dim)\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.pwconv1 = nn.Linear(dim, expansion*dim)\n",
    "        self.act = nn.GELU()\n",
    "        self.pwconv2 = nn.Linear(expansion*dim, dim)\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "        self.attn = ChannelAttention(dim)\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0 else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        input = x\n",
    "        x = self.dwconv(x)\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        x = self.norm1(x)\n",
    "        x = self.pwconv1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.pwconv2(x)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        x = input + self.drop_path(x)\n",
    "        x = x + self.drop_path(self.attn(self.norm2(x.permute(0,2,3,1)).permute(0,3,1,2)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e157c85-beff-45a3-a445-2163932867d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetaNet(nn.Module):\n",
    "    def __init__(self, in_chans=3, num_classes=1000, \n",
    "                 depths=[3, 3, 27, 3], dims=[128, 256, 512, 1024],\n",
    "                 drop_path_rate=0.4):\n",
    "        super().__init__()\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(in_chans, dims[0], 4, 4),\n",
    "            nn.GroupNorm(16, dims[0]),\n",
    "            nn.GELU()\n",
    "        )\n",
    "        \n",
    "        self.stages = nn.ModuleList()\n",
    "        dp_rates = [x.item() for x in torch.linspace(0, drop_path_rate, sum(depths))]\n",
    "        curr = 0\n",
    "        \n",
    "        for i in range(4):\n",
    "            stage = nn.Sequential(\n",
    "                *[HybridBlock(dims[i], drop_path=dp_rates[curr + j]) \n",
    "                  for j in range(depths[i])]\n",
    "            )\n",
    "            self.stages.append(stage)\n",
    "            curr += depths[i]\n",
    "            if i < 3:\n",
    "                self.stages.append(nn.Sequential(\n",
    "                    nn.Conv2d(dims[i], dims[i+1], 2, 2),\n",
    "                    nn.GroupNorm(16, dims[i+1]),\n",
    "                    nn.GELU()\n",
    "                ))\n",
    "        \n",
    "        self.head = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.LayerNorm(dims[-1]),\n",
    "            nn.Linear(dims[-1], num_classes)\n",
    "        )\n",
    "        \n",
    "        self.apply(self._init_weights)\n",
    "    \n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "            nn.init.trunc_normal_(m.weight, std=0.02)\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        for stage in self.stages:\n",
    "            x = stage(x)\n",
    "        return self.head(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac653823-1b63-41b8-81f6-1bb4167cb827",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropPath(nn.Module):\n",
    "    def __init__(self, drop_prob=0.):\n",
    "        super().__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.drop_prob == 0. or not self.training:\n",
    "            return x\n",
    "        keep_prob = 1 - self.drop_prob\n",
    "        shape = (x.shape[0],) + (1,) * (x.ndim - 1)\n",
    "        mask = torch.empty(shape, device=x.device).bernoulli_(keep_prob)\n",
    "        return x.div(keep_prob) * mask\n",
    "\n",
    "class EMA:\n",
    "    def __init__(self, model, decay):\n",
    "        self.model = model\n",
    "        self.decay = decay\n",
    "        self.shadow = {}\n",
    "        self.backup = {}\n",
    "        \n",
    "    def register(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.shadow[name] = param.data.clone()\n",
    "                \n",
    "    def update(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                new_average = (1.0 - self.decay) * param.data + self.decay * self.shadow[name]\n",
    "                self.shadow[name] = new_average.clone()\n",
    "    \n",
    "    def apply_shadow(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.backup[name] = param.data\n",
    "                param.data = self.shadow[name]\n",
    "    \n",
    "    def restore(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                param.data = self.backup[name]\n",
    "        self.backup = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cd399c-e4e7-490d-aa10-4fbc9b54d987",
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_transforms = [\n",
    "    CutMix(num_classes=1000),\n",
    "    MixUp(num_classes=1000)\n",
    "]\n",
    "\n",
    "rand_crop = Compose([\n",
    "    RandomResizedCrop(config.crop_size),\n",
    "    RandomHorizontalFlip(),\n",
    "    RandAugment(),\n",
    "    PILToTensor()\n",
    "])\n",
    "\n",
    "cent_crop = Compose([\n",
    "    Resize(config.valid_crop_size, interpolation=Image.Resampling.LANCZOS),\n",
    "    CenterCrop(config.valid_crop_size),\n",
    "    PILToTensor()\n",
    "])\n",
    "\n",
    "def train_collate_fn(batch):\n",
    "    B = len(batch)\n",
    "    x = torch.zeros((B, config.channels, config.crop_size, config.crop_size), dtype=torch.uint8)\n",
    "    y = torch.zeros(B, dtype=torch.long)\n",
    "    for i_sample, sample in enumerate(batch):\n",
    "        y[i_sample] = sample['cls']\n",
    "        x[i_sample] = rand_crop(sample['jpg'].convert(\"RGB\"))\n",
    "    x = x.float() / 255 - 0.5\n",
    "    return x, y\n",
    "\n",
    "def valid_collate_fn(batch):\n",
    "    B = len(batch)\n",
    "    x = torch.zeros((B, config.channels, config.valid_crop_size, config.valid_crop_size), dtype=torch.uint8)\n",
    "    y = torch.zeros(B, dtype=torch.long)\n",
    "    for i_sample, sample in enumerate(batch):\n",
    "        y[i_sample] = sample['cls']\n",
    "        x[i_sample] = cent_crop(sample['jpg'].convert(\"RGB\"))\n",
    "    x = x.float() / 255 - 0.5\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38e4395-cab2-4a2b-8396-246b4321b0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\"\n",
    "train_loader = DataLoader(load_dataset('timm/imagenet-1k-wds', split='train'),\n",
    "                         batch_size=config.batch_size, collate_fn=train_collate_fn,\n",
    "                         num_workers=32, shuffle=True, pin_memory=True)\n",
    "valid_loader = DataLoader(load_dataset('timm/imagenet-1k-wds', split='validation'),\n",
    "                         batch_size=config.batch_size*2, collate_fn=valid_collate_fn,\n",
    "                         num_workers=32, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60860e03-17b6-4371-ab62-f8b960c5d249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = MetaNet().to(device)\n",
    "\n",
    "print(sum(p.numel() for p in model.parameters())/1e6)\n",
    "\n",
    "ema = EMA(model, config.ema_decay)\n",
    "ema.register()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=config.label_smoothing)\n",
    "\n",
    "# Scheduler\n",
    "def lr_lambda(current_step):\n",
    "    if current_step < config.warmup_epochs * len(train_loader):\n",
    "        return (current_step + 1) / (config.warmup_epochs * len(train_loader))\n",
    "    progress = (current_step - config.warmup_epochs * len(train_loader)) / \\\n",
    "              ((config.epochs - config.warmup_epochs) * len(train_loader))\n",
    "    return 0.5 * (1 + math.cos(math.pi * progress))\n",
    "\n",
    "scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67fbfa2-84d3-48f9-9273-5bbe70b64250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "best_acc = 0.0\n",
    "for epoch in range(config.epochs):\n",
    "    model.train()\n",
    "    for step, (x, y) in enumerate(progress_bar(train_loader)):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        with torch.amp.autocast(device):\n",
    "            if np.random.rand() < 0.5:  # Mixup\n",
    "                x, y = mix_transforms[0](x, y)\n",
    "            else:\n",
    "                x, y = mix_transforms[1](x, y)\n",
    "            \n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "        \n",
    "        # Optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), config.grad_clip)\n",
    "        optimizer.step()\n",
    "        ema.update()\n",
    "        scheduler.step()\n",
    "        break\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    ema.apply_shadow()\n",
    "    total, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in progress_bar(valid_loader):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            with torch.amp.autocast(device):\n",
    "                logits = model(x)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            total += y.size(0)\n",
    "            correct += (preds == y).sum().item()\n",
    "    acc = 100 * correct / total\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "    ema.restore()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{config.epochs} | Val Acc: {acc:.2f}% | Best Acc: {best_acc:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
